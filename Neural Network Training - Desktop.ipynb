{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1106,
     "status": "ok",
     "timestamp": 1552065637216,
     "user": {
      "displayName": "Amable José Valdés Cuervo",
      "photoUrl": "",
      "userId": "15793518308995113839"
     },
     "user_tz": -60
    },
    "id": "17GFxxqYazHU",
    "outputId": "f72f8655-8424-44aa-b603-59916e13df90"
   },
   "source": [
    "# Neural Network (Desktop version)\n",
    "\n",
    "\n",
    "With this Jupyter notebook we can execute several operation to create, load or test a funtional Neural Network.\n",
    "\n",
    "This Notebook has been prepared to be used in your personal computer.\n",
    "\n",
    "You will need the train and validation data from the gitub repository for some operations. You will need a poweful computer to train the network. If you don't have one it will take too long. For old computer i recomend use the cloud: the Google Colab Jupyter Notebook and Google drive.\n",
    "\n",
    "\n",
    "## The Neural Network Architecture\n",
    "\n",
    "In this next cell you can see the architecture used in the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1448
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5248,
     "status": "ok",
     "timestamp": 1552057378299,
     "user": {
      "displayName": "Amable José Valdés Cuervo",
      "photoUrl": "",
      "userId": "15793518308995113839"
     },
     "user_tz": -60
    },
    "id": "nw1-wQ42a1Ll",
    "outputId": "a3996483-c444-468b-96b8-7cc4ddd8c73c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 72, 128, 128)      153728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 72, 128, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 72, 128, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 36, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 36, 64, 64)        409664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 36, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 36, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 18, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 32, 32)        102432    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 18, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 18, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 9, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 9, 16, 32)         25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 9, 16, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 9, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 2, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 713,031\n",
      "Trainable params: 712,391\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "\n",
    "# Data dimensions of our images.\n",
    "img_width, img_height = 128, 72\n",
    "\n",
    "# The architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, (20,20), padding='same', kernel_regularizer=regularizers.l2(0.0001), input_shape = (img_height, img_width,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (10,5), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (10,5), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (5,5), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "In this section we can train a new neural network or continue training an existing one.\n",
    "\n",
    "### Continue a training\n",
    "\n",
    "If you want to continue the training of a neural network you must load the neural network like you can see in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Neural_Network.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training configuration\n",
    "\n",
    "In the next cells there are several configuration parameters like the batch size or the number of epochs the network is going to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data ubication\n",
    "commonPath = \"\"\n",
    "train_data_dir = commonPath + 'dataset/train'\n",
    "validation_data_dir = commonPath + 'dataset/validation'\n",
    "\n",
    "# Training configuration\n",
    "nb_train_samples = 47000\n",
    "nb_validation_samples = 4700\n",
    "batch_size = 124\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we will upload the \"dataset / train\" data. There are many images, so ImageDataGenerator will be useful for that and will not break the computer's RAM. It is advisable to have checked the upper cell and made sure that the path where this folder is located is the correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42093 images belonging to 7 classes.\n",
      "Found 4679 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator( rotation_range = 180)\n",
    "\n",
    "# this is the augmentation configuration we will use for validation\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(72,128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(72,128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The epochs\n",
    "\n",
    "In this cell we will train our model. \n",
    "\n",
    "If we had used the previous model = load_model(commonPath + 'our_Neural_Network.h5') we can continue training a saved neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37011718,
     "status": "ok",
     "timestamp": 1552006493749,
     "user": {
      "displayName": "Amable José Valdés Cuervo",
      "photoUrl": "",
      "userId": "15793518308995113839"
     },
     "user_tz": -60
    },
    "id": "d1xk_vS1azHd",
    "outputId": "380c5b26-d8ec-409b-e4bc-e81ad33e0666"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "import time\n",
    "start = time.time()\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "end = time.time()\n",
    "\n",
    "model.save(commonURL + 'new_checkpoint.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Network.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
