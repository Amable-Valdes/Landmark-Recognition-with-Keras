{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-DId7C0Cswd"
   },
   "source": [
    "# Neural Network (Google Colab version)\n",
    "With this Jupyter notebook we can execute several operation to create, load or test a funtional Neural Network.\n",
    "\n",
    "This Notebook has been prepared to be used in Google Colab and, due to this, it is necessary to use a Google Drive account.\n",
    "\n",
    "It is also necessary to upload training and validation data in your Google Drive (more or less 100 MB). The upload time can be high (a couple of hours), but in google colab you can use a powerful GPU that some people (like me) can not afford, thus decreasing the training time of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_9YRcY2_C8Zk"
   },
   "source": [
    "## Google Drive access\n",
    "To use this notebook in google colab, you need to use your Google Drive account. You have to give Google rights to see, read and write on your Drive. Run this cell and you can work with your Google Drive data.\n",
    "\n",
    "Remember to put in \"commonURL\" the path to the directory where all the data is upload. I recommend this structure:\n",
    "\n",
    "Main\n",
    "\n",
    "| - data\n",
    "\n",
    "    | - train\n",
    "    | - validation\n",
    "    | - test\n",
    "\n",
    "| - Neural_Network.h5\n",
    "\n",
    "| - This_Notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MtVT78hJCuVd",
    "outputId": "fc67a75c-fe2b-4e4c-b8ed-d5c97de0e15a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WqO6Mm0Vcs-d",
    "outputId": "4a4333a0-165a-4530-f7d8-ae0295aabb39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train  validation\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/My Drive/TFM/dataset\"\n",
    "\n",
    "\"\"\"\n",
    "    Remember to change this Path\n",
    "\"\"\"\n",
    "commonURL = \"/content/drive/My Drive/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y96vv6kKDJi_"
   },
   "source": [
    "## The Neural Network Architecture\n",
    "\n",
    "In this next cell you can see the architecture used in the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "colab_type": "code",
    "id": "nw1-wQ42a1Ll",
    "outputId": "ec58af8b-bd8f-4fc2-bbd9-9b9ef2b53fba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 72, 128, 128)      153728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 72, 128, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 72, 128, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 36, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 36, 64, 64)        409664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 36, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 36, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 18, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 18, 32, 32)        102432    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 18, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 18, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 9, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 9, 16, 32)         25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 9, 16, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 9, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 4, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 2, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 2, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 2, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 2, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 713,031\n",
      "Trainable params: 712,391\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.applications import vgg16\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "\n",
    "# Data dimensions of our images.\n",
    "img_width, img_height = 128, 72\n",
    "\n",
    "# The architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, (20,20), padding='same', kernel_regularizer=regularizers.l2(0.0001), input_shape = (img_height, img_width,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (10,5), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (10,5), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (5,5), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLUnmzFvDRoa"
   },
   "source": [
    "## Training\n",
    "\n",
    "In this section we can train a new neural network or continue training an existing one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JA83E57kZ8DU"
   },
   "source": [
    "\n",
    "### Continue a training\n",
    "\n",
    "If you want to continue the training of a neural network you must load the neural network like you can see in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YihZUz4FZ5iY"
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOHlmfyFZ_8Z"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Neural_Network.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QDp8P4EFaAdc"
   },
   "source": [
    "### Training configuration\n",
    "In the next cells there are several configuration parameters like the batch size or the number of epochs the network is going to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUhtLABoBHg7"
   },
   "outputs": [],
   "source": [
    "# Training data ubication\n",
    "train_data_dir = commonURL + 'dataset/train'\n",
    "validation_data_dir = commonURL + 'dataset/validation'\n",
    "\n",
    "# Training configuration\n",
    "nb_train_samples = 45000\n",
    "nb_validation_samples = 4700\n",
    "batch_size = 124\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nmPKYBddI-lw"
   },
   "source": [
    "In this cell we will upload the \"dataset / train\" data. There are many images, so ImageDataGenerator will be useful for that and will not break the computer's RAM. It is advisable to have checked the upper cell and made sure that the path where this folder is located is the correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "d1xk_vS1azHd",
    "outputId": "3d75e09c-3ee2-4501-878e-ed260f50e243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42093 images belonging to 7 classes.\n",
      "Found 4679 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator( \n",
    "    rotation_range = 180,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2)\n",
    "\n",
    "# this is the augmentation configuration we will use for validation\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(72,128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(72,128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRsueI3EKDon"
   },
   "source": [
    "### The epochs\n",
    "In this cell we will train our model.\n",
    "\n",
    "If we had used the previous model = load_model(commonURL + 'our_Neural_Network.h5') we can continue training a saved neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "ytZYLRvcSZkm",
    "outputId": "6f0451bb-4f90-4e4b-c220-461405beaa76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "339/339 [==============================] - 216s 639ms/step - loss: 0.0756 - acc: 0.9919 - val_loss: 0.4593 - val_acc: 0.9207\n",
      "Epoch 2/10\n",
      "339/339 [==============================] - 210s 620ms/step - loss: 0.0767 - acc: 0.9917 - val_loss: 0.1276 - val_acc: 0.9769\n",
      "Epoch 3/10\n",
      "339/339 [==============================] - 207s 611ms/step - loss: 0.0752 - acc: 0.9916 - val_loss: 0.0772 - val_acc: 0.9901\n",
      "Epoch 4/10\n",
      "339/339 [==============================] - 209s 615ms/step - loss: 0.0698 - acc: 0.9937 - val_loss: 0.0879 - val_acc: 0.9849\n",
      "Epoch 5/10\n",
      "339/339 [==============================] - 209s 617ms/step - loss: 0.0868 - acc: 0.9875 - val_loss: 0.0599 - val_acc: 0.9982\n",
      "Epoch 6/10\n",
      "339/339 [==============================] - 208s 613ms/step - loss: 0.0695 - acc: 0.9942 - val_loss: 0.0706 - val_acc: 0.9932\n",
      "Epoch 7/10\n",
      "339/339 [==============================] - 207s 611ms/step - loss: 0.0727 - acc: 0.9922 - val_loss: 0.0950 - val_acc: 0.9866\n",
      "Epoch 8/10\n",
      "339/339 [==============================] - 207s 611ms/step - loss: 0.0765 - acc: 0.9910 - val_loss: 0.7263 - val_acc: 0.8562\n",
      "Epoch 9/10\n",
      "339/339 [==============================] - 209s 617ms/step - loss: 0.0690 - acc: 0.9937 - val_loss: 0.1127 - val_acc: 0.9794\n",
      "Epoch 10/10\n",
      "339/339 [==============================] - 204s 603ms/step - loss: 0.0654 - acc: 0.9943 - val_loss: 0.0680 - val_acc: 0.9923\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import time\n",
    "start = time.time()\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "end = time.time()\n",
    "\n",
    "model.save(commonURL + 'new_checkpoint.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Network.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
