{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Tests\n",
    "\n",
    "This jupyter notebook allows you to treat a video so that in its upper left corner appears the name of the label that the neural network thinks you are seeing at that moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# OS imports\n",
    "import glob\n",
    "import os,shutil\n",
    "import re\n",
    "# Keras imports\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image as preprocessing\n",
    "# Image processing imports\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageOps\n",
    "import numpy as np\n",
    "import cv2\n",
    "# Other\n",
    "import time\n",
    "\n",
    "# My directories paths\n",
    "commonPath = \"\"\n",
    "videos = commonPath + \"Dynamic Tests/Originals\"\n",
    "saveInDir = commonPath + \"Dynamic Tests/Results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Map\n",
    "\n",
    "In this cell we will map our video frames.\n",
    "\n",
    "With a \"for\" i'm going to iterate and between X and Y frames i will assign a Z label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapVideoTest1=[]\n",
    "numTotalFrames = 4282\n",
    "for i in range(0, 385):\n",
    "    mapVideoTest1.append(0)\n",
    "for i in range(385, 640):\n",
    "    mapVideoTest1.append(1)\n",
    "for i in range(640, 1260):\n",
    "    mapVideoTest1.append(2)\n",
    "for i in range(1260, 2950):\n",
    "    mapVideoTest1.append(4)\n",
    "for i in range(2950, 3600):\n",
    "    mapVideoTest1.append(5)\n",
    "for i in range(3600, 3980):\n",
    "    mapVideoTest1.append(6)\n",
    "for i in range(3980, numTotalFrames):\n",
    "    mapVideoTest1.append(3)\n",
    "    \n",
    "mapVideoTest2=[]\n",
    "numTotalFrames = 5512\n",
    "for i in range(0, 385):\n",
    "    mapVideoTest2.append(0)\n",
    "for i in range(385, 1100):\n",
    "    mapVideoTest2.append(1)\n",
    "for i in range(1100, 2050):\n",
    "    mapVideoTest2.append(2)\n",
    "for i in range(2050, 4200):\n",
    "    mapVideoTest2.append(4)\n",
    "for i in range(4200, 4900):\n",
    "    mapVideoTest2.append(5)\n",
    "for i in range(4900, 5350):\n",
    "    mapVideoTest2.append(6)\n",
    "for i in range(5350, numTotalFrames):\n",
    "    mapVideoTest2.append(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New video creation\n",
    "\n",
    "With all this funtions you can select a video and use your neural network to predict frame by frame what the neural network think is watching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testVideo(videoPath, realLabelsMap):\n",
    "    # We split the path and select nly the name of the .mp4\n",
    "    videoName = videoPath.split('/')[2]\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    \n",
    "    # We read the dimensions of the video and we minimize the new video size (less MB).\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    newVideoFramesSize = (int(frameWidth/5), int(frameHeight/5))\n",
    "    \n",
    "    # Temporal folder where we are going to sae the frames of the new video.\n",
    "    try:\n",
    "        os.stat('.temp')\n",
    "    except:\n",
    "        os.mkdir('.temp')\n",
    "    \n",
    "    totalTrues = 0\n",
    "    frameNumber = 0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            #for every frame of the video...\n",
    "            printAndRemove(\"Working on frame nº\" + str(frameNumber))\n",
    "            \n",
    "            # Preprocessing of the image for the Neural Network.\n",
    "            img = generateNeuralNetworkImage(frame, neuralNetworkImageSize)\n",
    "            # Use Neural Network to predict the node.\n",
    "            labelPredicted = translateNode(lookForBest(model.predict(img)))\n",
    "            # We update the accuracy.\n",
    "            if(translateNode(realLabelsMap[frameNumber]) == labelPredicted or realLabelsMap[frameNumber] == -1):\n",
    "                totalTrues = totalTrues + 1\n",
    "            # Write label in the new frame.\n",
    "            newFrame = generateNewVideoFrame(\n",
    "                frame, \n",
    "                newVideoFramesSize,\n",
    "                labelPredicted, \n",
    "                translateNode(realLabelsMap[frameNumber]), \n",
    "                totalTrues/(frameNumber+1)\n",
    "            )\n",
    "            \n",
    "            # Save new frame in temporal folder.\n",
    "            cv2.imwrite(\".temp/frame\" + str(frameNumber) + \".jpg\", cv2.cvtColor(newFrame, cv2.COLOR_BGR2RGB))\n",
    "            frameNumber = frameNumber + 1\n",
    "        else:\n",
    "            break\n",
    "    print(\"\")\n",
    "    \n",
    "    # We create the new video with the new frames from the temporal folder (with the label).\n",
    "    createNewVideoWithFrames(videoName, \".temp/*.jpg\", newVideoFramesSize)\n",
    "    # We move the video to the saveInDir folder.\n",
    "    shutil.move(videoName, saveInDir)\n",
    "    # Close all.\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # Remove temporal folder.\n",
    "    shutil.rmtree('.temp/')\n",
    "        \n",
    "    # Print results.\n",
    "    print(\"Video \\\"\" + videoName + \"\\\" ready\")\n",
    "    print(\"\\t-True Positives: \" + str(totalTrues))\n",
    "    print(\"\\t-Total Number Frames: \" + str(frameNumber))\n",
    "    print(\"\\t-Accuracy: \" + str(totalTrues/frameNumber))\n",
    "    \n",
    "# Print and remove the print\n",
    "def printAndRemove(msg):\n",
    "    print(msg, end=\"\\r\")\n",
    "    time.sleep(0)\n",
    "    \n",
    "# Select the label most likely to be true\n",
    "def lookForBest(prediction):\n",
    "    best = 0\n",
    "    categories = 6\n",
    "    for i,probability in enumerate(prediction[0]):\n",
    "        if probability > prediction[0][best]:\n",
    "            best = i\n",
    "    return best\n",
    "\n",
    "# Use the neural network to predict what can be the image\n",
    "def predictImg(img,realLabel,model):\n",
    "    prediction = model.predict(img)\n",
    "    return lookForBest(prediction)\n",
    "\n",
    "# Translate the label number to his string\n",
    "def translateNode(node):\n",
    "    if node == 0:\n",
    "        return \"Hall - Resident Rooms\"\n",
    "    if node == 1:\n",
    "        return \"Hall - Stairs\"\n",
    "    if node == 2:\n",
    "        return \"Building - Dinning room\"\n",
    "    if node == 3:\n",
    "        return \"Building - Rooms\"\n",
    "    if node == 4:\n",
    "        return \"Parking\"\n",
    "    if node == 5:\n",
    "        return \"Building - Library\"\n",
    "    if node == 6:\n",
    "        return \"Building - Gym\"\n",
    "    return \"Unknown\"\n",
    "    \n",
    "# The image must be refined before used in the neural network. It must have the right dimensions.\n",
    "def generateNeuralNetworkImage(image, size):\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(img).convert('RGB')\n",
    "    img = img.rotate(180)\n",
    "    img.thumbnail(neuralNetworkImageSize, Image.ANTIALIAS)\n",
    "    img = np.rot90(img)\n",
    "    img = Image.fromarray(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "    \n",
    "# We create the new frame and we write the text we need on it.\n",
    "def generateNewVideoFrame(frame, size, labelPredicted, labelReal, accuracy, ):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = Image.fromarray(frame).convert('RGB')\n",
    "    frame = frame.rotate(180)\n",
    "    frame.thumbnail(size, Image.ANTIALIAS)\n",
    "    frameDraw = ImageDraw.Draw(frame)\n",
    "    frameDraw.text( (5, 5) , \"Prediction:   \" + labelPredicted,  font = ImageFont.truetype(\"arial.ttf\", 12), fill=(255,255,255))\n",
    "    frameDraw.text( (5, 20) , \"Real Label: \" + labelReal,  font = ImageFont.truetype(\"arial.ttf\", 12), fill=(255,255,255))\n",
    "    frameDraw.text( (5, 35) , \"Accuracy: \" + str(accuracy),  font = ImageFont.truetype(\"arial.ttf\", 12), fill=(255,255,255))\n",
    "    frame = np.array(frame)\n",
    "    return frame\n",
    "\n",
    "# We iterate in every frame from the temporal folder and write a new video.\n",
    "def createNewVideoWithFrames(newVideoName, dirFrames, videoSize):\n",
    "    video = cv2.VideoWriter(newVideoName, cv2.VideoWriter_fourcc(*'DIVX'), 30.0, videoSize)\n",
    "    filenames = glob.glob(dirFrames)\n",
    "    filenames.sort(key=recompile)\n",
    "\n",
    "    for i,image in enumerate(filenames):\n",
    "        printAndRemove(\"New Video - Working on frame nº\" + str(i))\n",
    "        video.write(cv2.imread(image))\n",
    "    video.release()\n",
    "    print(\"\")\n",
    "\n",
    "# Funtion to sort the images form the temporal folder.\n",
    "def recompile(name):\n",
    "    r= re.compile(\"(\\d+).*\").split(name)\n",
    "    return [int(y) if y.isdigit() else y for y in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on frame nº5511\n",
      "New Video - Working on frame nº5511\n",
      "Video \"test2.mp4\" ready\n",
      "\t-True Positives: 2893\n",
      "\t-Total Number Frames: 5512\n",
      "\t-Accuracy: 0.5248548621190131\n"
     ]
    }
   ],
   "source": [
    "model = load_model(commonPath + 'Neural_Network.h5')\n",
    "#neuralNetworkImageSize = (96, 54)\n",
    "neuralNetworkImageSize = (128, 72)\n",
    "\n",
    "# We execute the dinamic test code and create the new video.\n",
    "testVideo(videos + \"/test2.mp4\", mapVideoTest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
